// server.js

// --- 1. Ð˜ÐœÐŸÐžÐ Ð¢Ð« Ð˜ ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ ---
const express = require('express');
const axios = require('axios');
const multer = require('multer');
const fs = require('fs');
const { Readable } = require('stream'); // Ð”Ð»Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²
const FormData = require('form-data'); // Ð”Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð° Ð² Whisper
require('dotenv').config(); // Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¸Ð· .env

// Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Google Cloud TTS
const { TextToSpeechClient } = require('@google-cloud/text-to-speech'); 

const app = express();
const PORT = 5000;

// ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Multer: ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐµ 'uploads'
const upload = multer({ dest: 'uploads/' });

// ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ¹
const DEEPSEEK_API_KEY = process.env.DEEPSEEK_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const TTS_VOICE_ID = process.env.TTS_VOICE_ID; 

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° TTS
const ttsClient = new TextToSpeechClient(); 

// ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¿ÐºÐ¸ uploads
if (!fs.existsSync('uploads')) {
    fs.mkdirSync('uploads');
}

// --- 2. Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ API (ÐœÐžÐ¡Ð¢Ð« Ðš ÐžÐ‘Ð›ÐÐšÐ£) ---

/**
 * Ð¨ÐÐ“ 1: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ WAV Ð² Ð¢ÐµÐºÑÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Whisper (OpenAI API).
 */
async function callWhisperApi(filePath) {
    if (!OPENAI_API_KEY) {
        console.error("   [API] Error: OpenAI API Key not configured.");
        return null;
    }

    console.log(`   [API] Calling Whisper with file: ${filePath}`);
    
    const form = new FormData();
    form.append('file', fs.createReadStream(filePath));
    form.append('model', 'whisper-1');
    form.append('language', 'ru'); 

    try {
        const response = await axios.post('https://api.openai.com/v1/audio/transcriptions', form, {
            headers: {
                ...form.getHeaders(),
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
            },
        });
        return response.data.text;
    } catch (error) {
        console.error(`   [API] Whisper Error: ${error.message}`);
        return null;
    }
}

/**
 * Ð¨ÐÐ“ 2: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð˜Ð˜ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ DeepSeek.
 */
async function callDeepseekApi(textPrompt) {
    console.log(`   [API] Calling DeepSeek with prompt: ${textPrompt}`);
    
    const SYSTEM_PROMPT = "Ð¢Ñ‹ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð² ÑƒÐ¼Ð½Ñ‹Ñ… Ð¾Ñ‡ÐºÐ°Ñ…. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ 40 ÑÐ»Ð¾Ð², Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.";
    
    try {
        const response = await axios.post('https://api.deepseek.com/v1/chat/completions', {
            model: "deepseek-chat", 
            messages: [
                { role: "system", content: SYSTEM_PROMPT },
                { role: "user", content: textPrompt }
            ],
            max_tokens: 100 
        }, {
            headers: {
                'Authorization': `Bearer ${DEEPSEEK_API_KEY}`,
                'Content-Type': 'application/json'
            }
        });

        if (response.status !== 200 || !response.data.choices || response.data.choices.length === 0) {
            console.error(`   [API] DeepSeek Error: ${response.status}, ${JSON.stringify(response.data)}`);
            return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñƒ Ð¼ÐµÐ½Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ð¼ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð¾Ð¼.";
        }
        
        return response.data.choices[0].message.content;
        
    } catch (error) {
        console.error(`   [API] DeepSeek Request Error: ${error.message}`);
        return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð½Ðµ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼Ñƒ ÑÐµÑ€Ð²ÐµÑ€Ñƒ.";
    }
}

/**
 * Ð¨ÐÐ“ 3: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐÑƒÐ´Ð¸Ð¾ Ð¸Ð· Ð¢ÐµÐºÑÑ‚Ð° (TTS) Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Google Cloud TTS.
 * Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Readable Stream (Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…).
 */
async function callTtsApi(textToSpeak) {
    console.log(`   [API] Calling GCTTS with text: ${textToSpeak}`);

    const request = {
        input: { text: textToSpeak },
        // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸Ð· .env
        voice: { languageCode: 'ru-RU', name: TTS_VOICE_ID || 'ru-RU-Wavenet-D' },
        // Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ MP3
        audioConfig: { audioEncoding: 'MP3' },
    };

    try {
        const [response] = await ttsClient.synthesizeSpeech(request);

        if (!response.audioContent) {
            throw new Error("TTS failed to generate audio.");
        }

        // ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾-Ð±ÑƒÑ„ÐµÑ€Ð° Ð² Ð¿Ð¾Ñ‚Ð¾Ðº (Stream)
        const audioBuffer = response.audioContent;
        const audioStream = new Readable();
        audioStream.push(audioBuffer);
        audioStream.push(null); // Ð¡Ð¸Ð³Ð½Ð°Ð» ÐºÐ¾Ð½Ñ†Ð° Ð¿Ð¾Ñ‚Ð¾ÐºÐ°
        
        return audioStream;

    } catch (error) {
        console.error(`   [API] GCTTS Request Error: ${error.message}`);
        throw new Error("TTS service failed."); 
    }
}


// --- 3. ÐžÐ¡ÐÐžÐ’ÐÐžÐ™ Ð­ÐÐ”ÐŸÐžÐ˜ÐÐ¢ Ð”Ð›Ð¯ ESP32 ---
app.post('/api/voice', upload.single('audio_file'), async (req, res) => {
    
    // ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¿ÑƒÑ‚Ð¸ Ðº Ñ„Ð°Ð¹Ð»Ñƒ
    const filePath = req.file ? req.file.path : null;
    console.log(`\n[Core] New request received. File path: ${filePath}`);

    if (!filePath) {
        return res.status(400).send({ error: "No audio file provided. Field name must be 'audio_file'." });
    }

    try {
        // 2. Ð¨ÐÐ“: STT (Whisper)
        const transcribedText = await callWhisperApi(filePath);
        
        let finalResponseText;
        if (!transcribedText || transcribedText.trim() === '') {
             console.log("[Core] STT failed or returned empty. Using fallback.");
             finalResponseText = "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð²Ð°Ñ ÑƒÑÐ»Ñ‹ÑˆÐ°Ñ‚ÑŒ. ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°.";
        } else {
             console.log(`[Core] Transcribed: "${transcribedText}"`);
             
             // 3. Ð¨ÐÐ“: LLM (DeepSeek)
             finalResponseText = await callDeepseekApi(transcribedText);
        }
        
        // 4. Ð¨ÐÐ“: TTS (Ð¡Ð¸Ð½Ñ‚ÐµÐ· Ð ÐµÑ‡Ð¸)
        const audioStream = await callTtsApi(finalResponseText); 

        // 5. ÐŸÐžÐ¢ÐžÐšÐžÐ’Ð«Ð™ ÐžÐ¢Ð’Ð•Ð¢ ÐÐ ESP32
        console.log("[Core] Starting stream response to ESP32...");
        
        // ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ð¸ MP3
        res.setHeader('Content-Type', 'audio/mpeg');
        res.setHeader('Transfer-Encoding', 'chunked'); 
        
        // ÐŸÐµÑ€ÐµÐ½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾Ð¿Ð¾Ñ‚Ð¾Ðº Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð² Ð¾Ñ‚Ð²ÐµÑ‚ (res)
        audioStream.pipe(res);
        
        // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¸ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°
        audioStream.on('error', (err) => {
            console.error("Audio stream error:", err);
            res.end();
        });
        
        audioStream.on('end', () => {
            console.log("[Core] Stream finished.");
        });

    } catch (e) {
        console.error(`[Core] Server Processing Error: ${e.message}`);
        res.status(500).send({ error: `Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°: ${e.message}` });
    } finally {
        // ÐžÐ§Ð˜Ð¡Ð¢ÐšÐ: Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°
        if (filePath && fs.existsSync(filePath)) {
            fs.unlink(filePath, (err) => {
                if (err) console.error("File cleanup failed:", err);
                else console.log(`[Core] Cleaned up file: ${filePath}`);
            });
        }
    }
});


// --- 4. Ð—ÐÐŸÐ£Ð¡Ðš Ð¡Ð•Ð Ð’Ð•Ð Ð ---
app.listen(PORT, '0.0.0.0', () => {
    console.log("-----------------------------------------------------");
    console.log(`ðŸ”¥ AI RELAY SERVER (NODE.JS) IS RUNNING ON http://0.0.0.0:${PORT} ðŸ”¥`);
    console.log("Connect ESP32 to http://[YOUR_IP]:5000/api/voice");
    console.log("-----------------------------------------------------");
});